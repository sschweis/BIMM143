---
title: 'Class 9: Unsupervised Learning Project'
author: "Sandy Schweis"
date: "4/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Exploratory data analysis

```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
```

```{r}
head(wisc.df)
```

# Convert the features of the data: wisc.data
```{r}
wisc.data <- as.matrix(wisc.df[,3:32])
```

# Set the row names of wisc.data
```{r}
row.names(wisc.data) <- wisc.df$id
head(wisc.data)
```

# Create diagnosis vector
```{r}
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
```

Q2. How many variables/features in the data are suffixed with _mean?
```{r}
colnames(wisc.data)
```

```{r}
length( grep("_mean", colnames(wisc.data) ) )
```

## Performing PCA

```{r}
round(colMeans(wisc.data), 1)
```

```{r}
round( apply(wisc.data, 2, sd) )
```

```{r}
wisc.pr <- prcomp(wisc.data, scale= TRUE)
summary(wisc.pr)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col= diagnosis+1)
```

```{r}
biplot(wisc.pr)
```


```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col= diagnosis+1,
     xlab = "PC1", ylab = "PC2")
```

# Calculate variance of each component
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

# Variance explained by each principal component: pve
```{r}
pve <- pr.var/ sum(pr.var)
head(pve)
```


# Plot variance explained for each principal component
```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

# Alternative scree plot of the same data, note data driven y-axis
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```


# Plot cumulative proportion of variance explained
```{r}
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


# Plot cumulative proportion of variance explained
```{r}
plot(pve , xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
par(mfcol=c(1,2))
plot(pve , xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

```


```{r}
library(factoextra)
```

```{r}
fviz_eig(wisc.pr, addlabels = TRUE)
```

```{r}
wisc.pr$rotation[,1]
```



##Hierarchical Clustering

```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled, method = "euclidean")
```

```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```

##Combining methods: CLustering on PCA results

Using the minimum number of principal components required to describe at least 90% of the variability in the data, creae a hierarchical clustering model with the linkage method = "ward.D2"
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method= "ward.D2")
```

```{r}
plot(wisc.pr.hclust)
```


```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis+1)
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```


## Prediction 

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16)
```

```{r}

```








